{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 安装环境\n",
    "\n",
    "- 系统：centos8\n",
    "- JDK：1.8_231\n",
    "- hadoop: 3.2.1\n",
    "\n",
    "### 2. 主机准备\n",
    "\n",
    "- 主机名： hadoop\n",
    "- vi /etc/hostname\n",
    "- 主机名与IP地址映射： /etc/hosts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # vi /etc/hosts\n",
    "    \n",
    "    IP地址   hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 防火墙关闭\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # systemctl status firewalld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 创建hadoop用户，命令如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # useradd hadoop\n",
    "    # passwd hadoop \n",
    "    \n",
    "    输入2遍【hadoop】"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- hadoop用户环境变量，配置JDK； /home/hadoop/.bash_profile\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 安装hadoop\n",
    "\n",
    "- 配置hadoop用户的免密码登录（ssh）\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ cd ~\n",
    "    \n",
    "    $ ssh-keygen -t rsa  [一路回车]\n",
    "    Generating public/private rsa key pair.\n",
    "    Enter file in which to save the key (/home/hadoop/.ssh/id_rsa): \n",
    "    Enter passphrase (empty for no passphrase): \n",
    "    Enter same passphrase again: \n",
    "    Your identification has been saved in /home/hadoop/.ssh/id_rsa.\n",
    "    Your public key has been saved in /home/hadoop/.ssh/id_rsa.pub.\n",
    "    The key fingerprint is:\n",
    "    SHA256:rHZD+W4NlnaUpIxIQ0Z4BQopVRv+8R7plMZNysmiOUg hadoop@hadoop\n",
    "    The key's randomart image is:\n",
    "    +---[RSA 2048]----+\n",
    "    | .ooo+=o.        |\n",
    "    |. .o.=+     .    |\n",
    "    | .  +o.o o.o .   |\n",
    "    |     ..B.Oo o    |\n",
    "    |  E   o S .o     |\n",
    "    | . . o O o= .    |\n",
    "    |  . + o =o.+     |\n",
    "    |     o . o. .    |\n",
    "    |         ..      |\n",
    "    +----[SHA256]-----+\n",
    "    \n",
    "    $ cd .ssh\n",
    "    $ cat id_rsa.pub >> authorized_keys\n",
    "    $ chmod 600 authorized_keys\n",
    "    $ chmod 700 ~/.ssh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 验证面密登录配置是否成功，命令："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ ssh hadoop\n",
    "    \n",
    "    $ exit\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 上传安装文件到指定目录，/home/hadoop/tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 解压tar.gz文件，并移动解压后的目录到指定位置，/usr/, 命令如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ tar zxvf hadoop-3.2.1.tar.gz\n",
    "    \n",
    "    $ ll\n",
    "    \n",
    "    总用量 540384\n",
    "    drwxr-xr-x. 9 hadoop hadoop       149 9月  11 2019 hadoop-3.2.1\n",
    "    -rwxrwxr-x. 1 hadoop hadoop 359196911 7月   7 11:19 hadoop-3.2.1.tar.gz\n",
    "        \n",
    "    $ exit\n",
    "    \n",
    "    # mv /home/hadoop/tools/hadoop-3.2.1 /usr/\n",
    "    \n",
    "    $ su - hadoop\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- hadoop环境变量配置，~/.bash_profile, 命令如下：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ vi ~/.bash_profile\n",
    "    \n",
    "    JAVA_HOME=/usr/jdk1.8.0_231\n",
    "    HADOOP_HOME=/usr/hadoop-3.2.1\n",
    "    PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$JAVA_HOME/bin:$PATH\n",
    "\n",
    "    export JAVA_HOME\n",
    "    export HADOOP_HOME\n",
    "    export PATH\n",
    "    \n",
    "    $ source .bash_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- hadoop的基本配置文件，hadoop-env.sh, 具体配置如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ cd /usr/hadoop-3.2.1/etc/hadoop\n",
    "    \n",
    "    $ vi hadoop-env.sh\n",
    "    \n",
    "    54 export JAVA_HOME=/usr/jdk1.8.0_231"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 测试基本配置是否完成，命令如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ hadoop version\n",
    "    Hadoop 3.2.1\n",
    "    Source code repository https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842\n",
    "    Compiled by rohithsharmaks on 2019-09-10T15:56Z\n",
    "    Compiled with protoc 2.5.0\n",
    "    From source with checksum 776eaf9eee9c0ffc370bcbc1888737\n",
    "    This command was run using /usr/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 准备目录，/usr/local/hadoop,用于job执行的临时文件目录，和数据存储\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # cd /usr/local\n",
    "    # mkdir hadoop\n",
    "    # chown -R hadoop:hadoop hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 核心配置（1）core-site.xml, $HADOOP_HOME/etc/hadoop/core-site.xml, 具体配置内容：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ vi /usr/hadoop-3.2.1/etc/hadoop/core-site.xml \n",
    "    \n",
    "    <configuration>\n",
    "    <!-- 指定HDFS路径地址，hadoop是与IP映射的主机名，9000是端口号 -->\n",
    "    <property>\n",
    "        <name>fs.defaultFS</name>\n",
    "        <value>hdfs://hadoop:9000</value>\n",
    "    </property>\n",
    "\n",
    "    <!-- 指定hadoop运行过程中产生的文件存储目录 -->\n",
    "    <property>\n",
    "        <name>hadoop.tmp.dir</name>\n",
    "        <value>/usr/local/hadoop/tmp</value>\n",
    "    </property>\n",
    "    </configuration>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 核心配置（2）hdfs-site.xml,$HADOOP_HOME/etc/hadoop目录下，具体配置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<!-- 文件存储在hdfs上的副本数量-->\n",
    "<property>\n",
    "    <name>dfs.replication</name>\n",
    "    <value>1</value>\n",
    "</property>\n",
    "<!-- hdfs web监听端口-->\n",
    "<property>\n",
    "    <name>dfs.namenode.http-address</name>\n",
    "    <value>hadoop:9870</value>\n",
    "</property>\n",
    "\n",
    "\n",
    "<!-- namenode数据存储路径 -->\n",
    "<property>\n",
    "    <name>dfs.namenode.name.dir</name>\n",
    "    <value>/usr/local/hadoop/dfs/name</value>\n",
    "</property>\n",
    "\n",
    "<!-- datanode数据存储路径 -->\n",
    "<property>\n",
    "    <name>dfs.datanode.data.dir</name>\n",
    "    <value>/usr/local/hadoop/dfs/data</value>\n",
    "</property>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 核心配置（3）mapred-site.xml,具体配置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<property>\n",
    "    <name>mapreduce.framework.name</name>\n",
    "    <value>yarn</value>\n",
    "</property>\n",
    "\n",
    "<property>\n",
    "    <name>mapreduce.application.classpath</name>\n",
    "    <value>\n",
    "    /usr/hadoop-3.2.1/etc/hadoop:/usr/hadoop-3.2.1/share/hadoop/common/lib/*:/usr/hadoop-3.2.1/share/hadoop/common/*:/usr/hadoop-3.2.1/share/hadoop/hdfs:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/*:/usr/hadoop-3.2.1/share/hadoop/hdfs/*:/usr/hadoop-3.2.1/share/hadoop/mapreduce/lib/*:/usr/hadoop-3.2.1/share/hadoop/mapreduce/*:/usr/hadoop-3.2.1/share/hadoop/yarn:/usr/hadoop-3.2.1/share/hadoop/yarn/lib/*:/usr/hadoop-3.2.1/share/hadoop/yarn/*\n",
    "    </value>\n",
    "</property>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 核心配置（4）yarn-site.xml, 具体配置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<property>\n",
    "    <name>yarn.resourcemanager.hostname</name>\n",
    "    <value>hadoop</value>\n",
    "</property>\n",
    "<property>\n",
    "    <name>yarn.nodemanager.aux-services</name>\n",
    "    <value>mapreduce_shuffle</value>\n",
    "</property>\n",
    "<property>\n",
    "    <name>mapreduce.application.classpath</name>\n",
    "    <value>\n",
    "    /usr/hadoop-3.2.1/etc/hadoop:/usr/hadoop-3.2.1/share/hadoop/common/lib/*:/usr/hadoop-3.2.1/share/hadoop/common/*:/usr/hadoop-3.2.1/share/hadoop/hdfs:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/*:/usr/hadoop-3.2.1/share/hadoop/hdfs/*:/usr/hadoop-3.2.1/share/hadoop/mapreduce/lib/*:/usr/hadoop-3.2.1/share/hadoop/mapreduce/*:/usr/hadoop-3.2.1/share/hadoop/yarn:/usr/hadoop-3.2.1/share/hadoop/yarn/lib/*:/usr/hadoop-3.2.1/share/hadoop/yarn/*\n",
    "    </value>\n",
    "</property>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 核心配置（5）workers，具体配置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 启动hadoop集群（伪分布式）\n",
    "\n",
    "- 首次启动hadoop，必须namenode格式化，命令如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ hdfs namenode -format\n",
    "    \n",
    "    2020-07-07 14:25:59,234 INFO common.Storage: Storage directory /usr/local/hadoop/dfs/name has been successfully formatted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 启动两个服务（HDFS、yarn），命令如下：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ start-dfs.sh\n",
    "    \n",
    "    $ start-yarn.sh\n",
    "    \n",
    "    $ jps\n",
    "    \n",
    "    14337 Jps\n",
    "    11608 jar\n",
    "    13610 SecondaryNameNode\n",
    "    13867 ResourceManager\n",
    "    13388 DataNode\n",
    "    13261 NameNode\n",
    "    13997 NodeManager\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HDFS管理命令\n",
    "\n",
    "    1. hdfs安全模式查看\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        $ hdfs dfsadmin -safemode get\n",
    "    \n",
    "        Safe mode is OFF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        注意：Safe mode is OFF，说明HDFS安全模式已经关闭，实现对数据的读写操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. 查看根目录结构，命令如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. 创建目录，命令如下：\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ hdfs dfs -mkdir /data\n",
    "    \n",
    "    $ hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4. 递归创建目录，命令如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ hdfs dfs -mkdir -p /data/subdata/input\n",
    "    \n",
    "    $ hdfs dfs -ls -R /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    5. 上传本地文件到hdfs指定目录，命令如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ hdfs dfs -put jdk-8u231-linux-x64.tar.gz /data/\n",
    "    \n",
    "    $ hdfs dfs -ls /data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    6. 下载hdfs数据文件到本地操作系统，命令如下：\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ hdfs dfs -get /data/jdk-8u231-linux-x64.tar.gz ./\n",
    "    \n",
    "    $ ll\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    7. 复制文件，命令如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ hdfs dfs -cp /data/jdk-8u231-linux-x64.tar.gz /data/subdata/jdk.tar.gz\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    8. 删除文件，命令如下：\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ hdfs dfs -rm -r /data/subdata/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. HDFS管理命令\n",
    "\n",
    "- 安全模式\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ hdfs dfsadmin -safemode get\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    hdfs dfsadmin -safemode get|enter|leave|wait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- report命令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ hdfs dfsadmin -report\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Configured Capacity: 37558423552 (34.98 GB)\n",
    "Present Capacity: 29635686400 (27.60 GB)\n",
    "DFS Remaining: 29440000000 (27.42 GB)\n",
    "DFS Used: 195686400 (186.62 MB)\n",
    "DFS Used%: 0.66%\n",
    "Replicated Blocks:\n",
    "        Under replicated blocks: 0\n",
    "        Blocks with corrupt replicas: 0\n",
    "        Missing blocks: 0\n",
    "        Missing blocks (with replication factor 1): 0\n",
    "        Low redundancy blocks with highest priority to recover: 0\n",
    "        Pending deletion blocks: 0\n",
    "Erasure Coded Block Groups: \n",
    "        Low redundancy block groups: 0\n",
    "        Block groups with corrupt internal blocks: 0\n",
    "        Missing block groups: 0\n",
    "        Low redundancy blocks with highest priority to recover: 0\n",
    "        Pending deletion blocks: 0\n",
    "\n",
    "-------------------------------------------------\n",
    "Live datanodes (1):\n",
    "\n",
    "Name: 192.168.1.103:9866 (hadoop)\n",
    "Hostname: hadoop\n",
    "Decommission Status : Normal\n",
    "Configured Capacity: 37558423552 (34.98 GB)\n",
    "DFS Used: 195686400 (186.62 MB)\n",
    "Non DFS Used: 7922737152 (7.38 GB)\n",
    "DFS Remaining: 29440000000 (27.42 GB)\n",
    "DFS Used%: 0.52%\n",
    "DFS Remaining%: 78.38%\n",
    "Configured Cache Capacity: 0 (0 B)\n",
    "Cache Used: 0 (0 B)\n",
    "Cache Remaining: 0 (0 B)\n",
    "Cache Used%: 100.00%\n",
    "Cache Remaining%: 0.00%\n",
    "Xceivers: 1\n",
    "Last contact: Tue Jul 07 14:54:09 CST 2020\n",
    "Last Block Report: Tue Jul 07 14:28:45 CST 2020\n",
    "Num of Blocks: 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
