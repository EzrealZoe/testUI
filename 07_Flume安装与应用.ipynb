{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Flume概述\n",
    "\n",
    "- 日志采集和汇总工具\n",
    "- 收集到的日志数据汇总到HDFS存储\n",
    "\n",
    "### 2. 安装文件\n",
    "\n",
    "- 云盘\n",
    "- 官方下载\n",
    "- flume：1.9.0\n",
    "\n",
    "\n",
    "### 3.  Flume组件\n",
    "\n",
    "- source：数据源（需要采集的数据）\n",
    "- channel：临时存储的数据位置，通常存储在内存中\n",
    "- sink：数据目标存储，hdfs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 安装Flume\n",
    "\n",
    "- 上传安装文件到服务器\n",
    "- 解压安装，命令如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ tar zxvf apache-flume-1.9.0-bin.tar.gz\n",
    "    \n",
    "    $ ll\n",
    "    \n",
    "    drwxrwxr-x. 7 hadoop hadoop       187 7月   7 17:22 apache-flume-1.9.0-bin\n",
    "    -rwxrwxr-x. 1 hadoop hadoop  67938106 7月   7 17:21 apache-flume-1.9.0-bin.tar.gz\n",
    "    -rwxrwxr-x. 1 hadoop hadoop 359196911 7月   7 11:19 hadoop-3.2.1.tar.gz\n",
    "    -rw-r--r--. 1 hadoop hadoop 194151339 7月   7 14:46 jdk-8u231-linux-x64.tar.gz\n",
    "        \n",
    "    $ exit\n",
    "    \n",
    "    # mv apache-flume-1.9.0-bin /usr/\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 配置环境变量，~/.bash_profile, 具体内容：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    JAVA_HOME=/usr/jdk1.8.0_231\n",
    "    HADOOP_HOME=/usr/hadoop-3.2.1\n",
    "    FLUME_HOME=/usr/apache-flume-1.9.0-bin\n",
    "    PATH=$FLUME_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$JAVA_HOME/bin:$PATH\n",
    "\n",
    "    export JAVA_HOME\n",
    "    export HADOOP_HOME\n",
    "    export FLUME_HOME\n",
    "    export PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    注意：source ~/.bash_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Flume基本配置，$FLUME_HOME/conf/flume-env.sh, 具体配置如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ cp flume-env.sh.template  flume-env.sh\n",
    "    $ vi flume-env.sh\n",
    "    \n",
    "    \n",
    "     22 export JAVA_HOME=/usr/jdk1.8.0_231"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 解决jar包冲突问题\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ cd /usr/apache-flume-1.9.0-bin/lib\n",
    "    $ ll guava-11.0.2.jar \n",
    "    -rw-rw-r--. 1 hadoop hadoop 1648200 9月  13 2018 guava-11.0.2.jar\n",
    "    \n",
    "    \n",
    "    $ cd /usr/hadoop-3.2.1/share/hadoop/common/lib\n",
    "    $ ll guava-27.0-jre.jar \n",
    "    -rw-r--r--. 1 hadoop hadoop 2747878 9月  10 2019 guava-27.0-jre.jar\n",
    "    \n",
    "    \n",
    "    $ rm -rf /usr/apache-flume-1.9.0-bin/lib/guava-11.0.2.jar \n",
    "    $ cp /usr/hadoop-3.2.1/share/hadoop/common/lib/guava-27.0-jre.jar /usr/apache-flume-1.9.0-bin/lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 实现数据同步\n",
    "\n",
    "- 功能需求\n",
    "\n",
    "    1. 采集爬虫服务器中的数据汇总到hdfs指定目录\n",
    "    \n",
    "- 实现步骤\n",
    "    1. 启动数据采集服务\n",
    "    2. 启动hdfs服务，保证hdfs可读写\n",
    "    3. 配置一个Agent（Source、Channel、Sink）\n",
    "    4. 使用flume1.7+版本新特性，source组件中提供了高可靠的同步模式(TIALDIR), 保证数据不丢失\n",
    "    5. 编写运行脚本(shell/sh)并执行\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ cd /usr/apache-flume-1.9.0-bin/\n",
    "    $ mkdir myconf\n",
    "    $ cd myconf\n",
    "    \n",
    "    $ vi flume-taildir-memory-hdfs.properties\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    创建agent配置文件\"flume-taildir-memory-hdfs.properties\", 具体配置如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Name the components on this agent\n",
    "hdfs_agent.sources = r1\n",
    "hdfs_agent.sinks = k1\n",
    "hdfs_agent.channels = c1\n",
    "\n",
    "# Describe/configure the source\n",
    "hdfs_agent.sources.r1.type = TAILDIR\n",
    "hdfs_agent.sources.r1.filegroups = f1\n",
    "hdfs_agent.sources.r1.filegroups.f1 = /home/hadoop/spider/data/collect/.*\\.log\n",
    "hdfs_agent.sources.r1.positionFile = /home/hadoop/spider/data/.flume/taildir_position.json\n",
    "\n",
    "# Describe the sink\n",
    "hdfs_agent.sinks.k1.type = hdfs\n",
    "hdfs_agent.sinks.k1.hdfs.path = hdfs://hadoop:9000/flume/hdfs_filegroups_source/%Y-%m-%d/\n",
    "hdfs_agent.sinks.k1.hdfs.rollInterval = 3600\n",
    "hdfs_agent.sinks.k1.hdfs.rollSize = 1048576\n",
    "hdfs_agent.sinks.k1.hdfs.rollCount = 0\n",
    "hdfs_agent.sinks.k1.hdfs.filePrefix = log_file_%H\n",
    "hdfs_agent.sinks.k1.hdfs.fileSuffix = .log\n",
    "hdfs_agent.sinks.k1.hdfs.fileType = DataStream\n",
    "hdfs_agent.sinks.k1.hdfs.useLocalTimeStamp = true\n",
    "\n",
    "# Use a channel which buffers events in memory\n",
    "hdfs_agent.channels.c1.type = memory\n",
    "hdfs_agent.channels.c1.capacity = 1000\n",
    "hdfs_agent.channels.c1.transactionCapacity = 100\n",
    "\n",
    "# Bind the source and sink to the channel\n",
    "hdfs_agent.sources.r1.channels = c1\n",
    "hdfs_agent.sinks.k1.channel = c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ hdfs dfs -mkdir -p /flume/hdfs_filegroups_source/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    编写shell脚本，安装目录下创建mysbin目录，start_taildir_memory_hdfs.sh ， 具体内容如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ cd /usr/apache-flume-1.9.0-bin/\n",
    "    $ mkdir mysbin\n",
    "    $ cd mysbin\n",
    "    $ vi start_taildir_memory_hdfs.sh\n",
    "    \n",
    "    \n",
    "    #!/bin/bash\n",
    "\n",
    "    ROOT_PATH=$(dirname $(dirname $(readlink -f $0)))\n",
    "    cd $ROOT_PATH\n",
    "\n",
    "    bin/flume-ng agent --conf ./conf/ -f myconf/flume-taildir-memory-hdfs.properties -Dflume.root.logger=INFO,console -n hdfs_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    更改脚本的执行权限，命令如下：\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ chmod 755 start_taildir_memory_hdfs.sh\n",
    "     ll\n",
    "    总用量 4\n",
    "    -rwxr-xr-x. 1 hadoop hadoop 206 7月   7 17:56 start_taildir_memory_hdfs.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    执行start_taildir_memory_hdfs.sh脚本文件，命令如下：\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $ nohup ./start_taildir_memory_hdfs.sh &\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
